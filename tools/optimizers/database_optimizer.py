#!/usr/bin/env python3
"""
Ù…Ø­Ø³Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
Advanced Database Optimizer
"""

import os
import sys
import time
import django
from pathlib import Path
from datetime import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯ Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'settings')
django.setup()

from django.db import connection, transaction
from django.core.management import call_command
from django.apps import apps


class DatabaseOptimizer:
    """Ù…Ø­Ø³Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ·ÙˆØ±"""
    
    def __init__(self):
        self.optimizations_applied = []
        self.performance_gains = {}
    
    def analyze_tables(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„...")
        
        with connection.cursor() as cursor:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name NOT LIKE 'sqlite_%'
                ORDER BY name
            """)
            tables = [row[0] for row in cursor.fetchall()]
            
            table_analysis = {}
            
            for table in tables:
                # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
                cursor.execute(f"SELECT COUNT(*) FROM `{table}`")
                row_count = cursor.fetchone()[0]
                
                # ÙØ­Øµ Ø§Ù„ÙÙ‡Ø§Ø±Ø³
                cursor.execute(f"PRAGMA index_list('{table}')")
                indexes = cursor.fetchall()
                index_count = len(indexes)
                
                # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
                cursor.execute(f"PRAGMA table_info('{table}')")
                columns = cursor.fetchall()
                column_count = len(columns)
                
                table_analysis[table] = {
                    'rows': row_count,
                    'indexes': index_count,
                    'columns': column_count
                }
                
                # Ø§Ù„ØªÙˆØµÙŠØ§Øª
                if row_count > 1000 and index_count < 2:
                    self.optimizations_applied.append(
                        f"âš ï¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ {table} ({row_count:,} Ø³Ø·Ø±) ÙŠØ­ØªØ§Ø¬ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙÙ‡Ø§Ø±Ø³"
                    )
                
                if row_count > 10000 and index_count < 3:
                    self.optimizations_applied.append(
                        f"ğŸ”¥ Ø§Ù„Ø¬Ø¯ÙˆÙ„ {table} ({row_count:,} Ø³Ø·Ø±) ÙŠØ­ØªØ§Ø¬ ÙÙ‡Ø±Ø³Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"
                    )
            
            print(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(tables)} Ø¬Ø¯ÙˆÙ„")
            return table_analysis
    
    def create_missing_indexes(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"""
        print("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©...")
        
        # ÙÙ‡Ø§Ø±Ø³ Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡
        suggested_indexes = [
            # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ±ØªÙŠØ¨
            "CREATE INDEX IF NOT EXISTS idx_user_email ON students_user(email)",
            "CREATE INDEX IF NOT EXISTS idx_user_username ON students_user(username)",
            "CREATE INDEX IF NOT EXISTS idx_user_date_joined ON students_user(date_joined)",
            "CREATE INDEX IF NOT EXISTS idx_user_role ON students_user(role)",
            
            # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
            "CREATE INDEX IF NOT EXISTS idx_attendance_session_date ON attendance_qr_attendancesession(scheduled_start_time)",
            "CREATE INDEX IF NOT EXISTS idx_attendance_record_date ON attendance_qr_attendancerecord(recorded_at)",
            "CREATE INDEX IF NOT EXISTS idx_security_event_date ON cyber_security_securityevent(created_at)",
            "CREATE INDEX IF NOT EXISTS idx_security_event_severity ON cyber_security_securityevent(severity)",
            
            # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
            "CREATE INDEX IF NOT EXISTS idx_attendance_record_student ON attendance_qr_attendancerecord(student_id)",
            "CREATE INDEX IF NOT EXISTS idx_attendance_record_session ON attendance_qr_attendancerecord(attendance_session_id)",
            "CREATE INDEX IF NOT EXISTS idx_security_event_user ON cyber_security_securityevent(affected_user_id)",
        ]
        
        created_count = 0
        with connection.cursor() as cursor:
            for index_sql in suggested_indexes:
                try:
                    cursor.execute(index_sql)
                    created_count += 1
                    index_name = index_sql.split()[4]  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³
                    self.optimizations_applied.append(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {index_name}")
                except Exception as e:
                    if "already exists" not in str(e):
                        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {e}")
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_count} ÙÙ‡Ø±Ø³ Ø¬Ø¯ÙŠØ¯")
        return created_count
    
    def optimize_queries(self):
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        print("âš¡ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª...")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        slow_queries = []
        
        with connection.cursor() as cursor:
            # ÙØ­Øµ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name NOT LIKE 'sqlite_%'
            """)
            tables = [row[0] for row in cursor.fetchall()]
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM `{table}`")
                row_count = cursor.fetchone()[0]
                
                if row_count > 1000:
                    # Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±Ø¹Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø³ÙŠØ·
                    start_time = time.time()
                    cursor.execute(f"SELECT * FROM `{table}` LIMIT 10")
                    cursor.fetchall()
                    query_time = time.time() - start_time
                    
                    if query_time > 0.01:  # Ø£ÙƒØ«Ø± Ù…Ù† 10ms
                        slow_queries.append({
                            'table': table,
                            'rows': row_count,
                            'time_ms': round(query_time * 1000, 2)
                        })
        
        if slow_queries:
            self.optimizations_applied.append("ğŸŒ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø·ÙŠØ¦Ø© ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§:")
            for query in slow_queries[:5]:  # Ø£ÙˆÙ„ 5 Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
                self.optimizations_applied.append(
                    f"   {query['table']}: {query['rows']:,} Ø³Ø·Ø± - {query['time_ms']}ms"
                )
        
        return len(slow_queries)
    
    def vacuum_and_analyze(self):
        """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        print("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        with connection.cursor() as cursor:
            # Ø­ÙØ¸ Ø­Ø¬Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
            db_path = Path(connection.settings_dict['NAME'])
            size_before = db_path.stat().st_size if db_path.exists() else 0
            
            # ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            start_time = time.time()
            cursor.execute("VACUUM")
            vacuum_time = time.time() - start_time
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            start_time = time.time()
            cursor.execute("ANALYZE")
            analyze_time = time.time() - start_time
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø­Ø±Ø±Ø©
            size_after = db_path.stat().st_size if db_path.exists() else 0
            space_saved = size_before - size_after
            
            self.optimizations_applied.extend([
                f"ğŸ§¹ VACUUM: {vacuum_time:.2f} Ø«Ø§Ù†ÙŠØ©",
                f"ğŸ“Š ANALYZE: {analyze_time:.2f} Ø«Ø§Ù†ÙŠØ©",
                f"ğŸ’¾ Ù…Ø³Ø§Ø­Ø© Ù…Ø­Ø±Ø±Ø©: {space_saved / 1024:.1f} KB"
            ])
            
            self.performance_gains['vacuum_time'] = vacuum_time
            self.performance_gains['space_saved_kb'] = space_saved / 1024
    
    def update_table_statistics(self):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
        print("ğŸ“ˆ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª...")
        
        with connection.cursor() as cursor:
            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª SQLite
            cursor.execute("PRAGMA optimize")
            self.optimizations_applied.append("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„")
    
    def check_foreign_keys(self):
        """ÙØ­Øµ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©"""
        print("ğŸ”— ÙØ­Øµ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©...")
        
        with connection.cursor() as cursor:
            cursor.execute("PRAGMA foreign_key_check")
            fk_errors = cursor.fetchall()
            
            if fk_errors:
                self.optimizations_applied.append(f"âš ï¸ {len(fk_errors)} Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©")
                for error in fk_errors[:5]:  # Ø£ÙˆÙ„ 5 Ø£Ø®Ø·Ø§Ø¡
                    self.optimizations_applied.append(f"   Ø®Ø·Ø£: {error}")
            else:
                self.optimizations_applied.append("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø³Ù„ÙŠÙ…Ø©")
    
    def optimize_django_settings(self):
        """ØªØ­Ø³ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Django"""
        print("âš™ï¸ ÙØ­Øµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Django...")
        
        from django.conf import settings
        
        # ÙØ­Øµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        db_config = settings.DATABASES['default']
        
        optimizations = []
        
        # ÙØ­Øµ conn_max_age
        if 'conn_max_age' not in db_config or db_config.get('conn_max_age', 0) == 0:
            optimizations.append("ğŸ’¡ ÙŠÙÙ†ØµØ­ Ø¨ØªÙØ¹ÙŠÙ„ connection pooling (conn_max_age)")
        
        # ÙØ­Øµ DEBUG
        if settings.DEBUG:
            optimizations.append("âš ï¸ DEBUG=True ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬")
        
        # ÙØ­Øµ CACHE
        cache_config = getattr(settings, 'CACHES', {}).get('default', {})
        if cache_config.get('BACKEND') == 'django.core.cache.backends.locmem.LocMemCache':
            optimizations.append("ğŸ’¡ ÙŠÙÙ†ØµØ­ Ø¨Ù€ Redis Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† LocMemCache")
        
        self.optimizations_applied.extend(optimizations)
        return len(optimizations)
    
    def generate_optimization_report(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'optimizations_applied': self.optimizations_applied,
            'performance_gains': self.performance_gains,
            'recommendations': [
                "ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… Redis Ù„Ù„Ù€ Cache ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬",
                "ğŸ’¡ ÙØ¹Ù‘Ù„ connection pooling",
                "ğŸ’¡ Ø±Ø§Ù‚Ø¨ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Django Ø§Ù„Ø·ÙˆÙŠÙ„Ø©",
                "ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… select_related() Ùˆ prefetch_related()",
                "ğŸ’¡ Ø£Ø¶Ù ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ WHERE Ùˆ ORDER BY"
            ]
        }
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_dir = Path('database_reports')
        report_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = report_dir / f'optimization_report_{timestamp}.json'
        
        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return report_file, report
    
    def run_full_optimization(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø´Ø§Ù…Ù„"""
        print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„...")
        print("=" * 60)
        
        start_time = time.time()
        
        # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
        table_analysis = self.analyze_tables()
        indexes_created = self.create_missing_indexes()
        slow_queries = self.optimize_queries()
        self.vacuum_and_analyze()
        self.update_table_statistics()
        self.check_foreign_keys()
        django_optimizations = self.optimize_django_settings()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_file, report = self.generate_optimization_report()
        
        end_time = time.time()
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“‹ ØªÙ‚Ø±ÙŠØ± ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        print("=" * 60)
        
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†: {end_time - start_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ“Š ÙÙ‡Ø§Ø±Ø³ Ø¬Ø¯ÙŠØ¯Ø©: {indexes_created}")
        print(f"ğŸŒ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø·ÙŠØ¦Ø©: {slow_queries}")
        print(f"âš™ï¸ ØªÙˆØµÙŠØ§Øª Django: {django_optimizations}")
        
        if self.performance_gains:
            print(f"ğŸ’¾ Ù…Ø³Ø§Ø­Ø© Ù…Ø­Ø±Ø±Ø©: {self.performance_gains.get('space_saved_kb', 0):.1f} KB")
        
        print(f"\nğŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {report_file}")
        
        print("\nğŸ”§ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©:")
        for opt in self.optimizations_applied:
            print(f"   {opt}")
        
        print("\nâœ… Ø§ÙƒØªÙ…Ù„ ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    optimizer = DatabaseOptimizer()
    optimizer.run_full_optimization()


if __name__ == "__main__":
    main()